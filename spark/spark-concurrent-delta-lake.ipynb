{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4f4ad-2683-4ce3-9805-b30f77022c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!wget https://github.com/databrickslabs/dbldatagen/archive/refs/tags/v.0.2.0-rc1-master.zip\n",
    "!pip install v.0.2.0-rc1-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938373cb-a509-4ffb-8eea-1c66fc00ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pls adjust:\n",
    "access_key = \"access_key\"\n",
    "secret_key = \"secret_key\"\n",
    "own_folder = \"tim\"\n",
    "shared_folder = \"shared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd224673-82a3-49b6-95d7-bad991b00091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/default-java\"\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"io.delta:delta-core_2.12:1.1.0,org.apache.hadoop:hadoop-aws:3.3.1\" pyspark-shell'\n",
    "\n",
    "import pyspark\n",
    "from delta import configure_spark_with_delta_pip\n",
    "\n",
    "namespace = os.environ[\"NAMESPACE\"] # usually \"firstname-lastname\"\n",
    "notebook_name = os.environ[\"NOTEBOOK_NAME\"] # might be helpful\n",
    "\n",
    "builder = (\n",
    "    pyspark.sql.SparkSession.builder.appName(f\"{namespace}-spark-app\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"miniotimrelease.miniotim:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", access_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", secret_key) \\\n",
    "    .config(\"spark.executor.instances\", \"1\") # number of Executors\n",
    "    .config(\"spark.executor.memory\", \"8g\") # Executor memory\n",
    "    .config(\"spark.executor.cores\", \"1\") # Executor cores\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9078d-2821-41f9-97a6-3bfe9e51f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification test\n",
    "spark.range(5).write.format(\"delta\").mode(\"overwrite\").save(f\"s3a://deltabucket/{own_folder}/delta-table-bench\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5a27a-1acf-4dfe-bf18-a1808bb3043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification test\n",
    "spark.read.format(\"delta\").load(f\"s3a://deltabucket/{own_folder}/delta-table-bench\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b5ace-930a-4d2c-a719-b153023c72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##concurrent test #1 ================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd757d-d71d-4525-85db-072dd3943bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import math\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "number_of_rows = 100000000\n",
    "num_digits = int(math.log10(number_of_rows)) + 1\n",
    "\n",
    "df = spark.range(1, number_of_rows+1)\n",
    "df = df.withColumn(\"value\", F.lit(own_folder))\n",
    "df = df.withColumn(\"value\", F.concat_ws(\"\", F.col(\"value\"), F.format_string(f\"%0{num_digits}d\", F.col(\"id\"))))\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(f\"s3a://deltabucket/{shared_folder}/thousand\")\n",
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be9ffc-e936-4e87-be26-aad25731c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification test\n",
    "read = spark.read.format(\"delta\").load(f\"s3a://deltabucket/{shared_folder}/thousand\")\n",
    "read.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d61896-4e08-4f0d-9174-fb83d6a3e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification test\n",
    "read.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c8d83-6785-4c41-9208-97f079df84ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3f01f-b33e-471d-932c-7a17868cdeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dbldatagen as dg\n",
    "\n",
    "schema = dg.SchemaParser.parseCreateTable(spark, \"\"\"\n",
    "    create table Test1 (\n",
    "    source string ,\n",
    "    language string ,\n",
    "    topic string ,\n",
    "    license string )\n",
    "\"\"\")\n",
    "\n",
    "data_rows = 4*10**9\n",
    "\n",
    "x3 = (dg.DataGenerator(sparkSession=spark, name=\"test_table_query\", rows=data_rows, partitions=20)\n",
    "      .withSchema(schema)\n",
    "      .withIdOutput()\n",
    "      .withColumnSpec(\"source\", values=[\"hackernews\", \"cc\", \"wikipedia\", \"academic\", \"books\", \"pubmed\", \"opensubtitiles\", \"youtubesubtitles\"], random=True)\n",
    "      .withColumnSpec(\"language\", values=[\"en\", \"de\", \"fr\", \"es\", \"ru\"], random=True)\n",
    "      .withColumnSpec(\"topic\", values=[\"software\", \"medical\", \"cultural\", \"academic\", \"hardware\", \"ai\", \"ml\", \"random\"], random=True)\n",
    "      .withColumnSpec(\"license\", values=[\"MIT\", \"GPL-v2\", \"GPL-v3\", \"private\", \"apache\", \"cc\"], random=True)\n",
    "     )\n",
    "\n",
    "x3_output_full = x3.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bbe06-cfe2-4487-aa5b-26dbeb977acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##concurrent test #2 ================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96738d5-312b-46e5-8f08-cc400d575693",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "start = time.monotonic_ns()\n",
    "#x3_output_full.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"test_data\")\n",
    "x3_output_full.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"test_data\", path='s3a://deltabucket/shared/delta-table-bench')\n",
    "print(\"Time elapsed : \", (time.monotonic_ns() - start)/10**9, \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c923016-c9f6-45a3-ae46-1f1624402e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verification test\n",
    "data_table = spark.table(\"test_data\")\n",
    "data_table.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
